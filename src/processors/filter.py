"""Layer 2: æ™ºèƒ½è¿‡æ»¤ - ç²—æ’ç²¾æ’ + å€™é€‰æ±  + å»é‡"""

import json
import math
import re
from typing import List, Dict, Tuple
from pathlib import Path
from collections import Counter

from sources.base import Item
from utils.time_utils import is_within_hours
from .filters import get_filter, FILTER_REGISTRY


# ============================================================
# è€æ¿å…³æ³¨é¢†åŸŸå…³é”®è¯ï¼ˆç”¨äº BM25 ç›¸å…³æ€§æ‰“åˆ†ï¼‰
# ============================================================
OWNER_INTEREST_KEYWORDS = {
    # AI / LLMï¼ˆæ ¸å¿ƒï¼‰
    'llm': 8, 'large language model': 8, 'gpt': 7, 'claude': 7, 'gemini': 6,
    'transformer': 7, 'attention': 5, 'rag': 7, 'agent': 6, 'reasoning': 6,
    'fine-tuning': 6, 'finetuning': 6, 'prompt': 5, 'embedding': 5,
    'multimodal': 6, 'vision language': 6, 'code generation': 6,
    'openai': 6, 'anthropic': 6, 'deepmind': 5, 'meta ai': 5,
    'open source': 5, 'open-source': 5, 'hugging face': 5, 'huggingface': 5,
    'inference': 5, 'quantization': 6, 'gguf': 5, 'ggml': 5, 'ollama': 5,
    'local llm': 7, 'vllm': 5, 'lora': 6, 'qlora': 6,
    'deep learning': 5, 'machine learning': 4, 'neural network': 4,
    'ai': 3, 'artificial intelligence': 4,
    # ä¸­æ–‡ AI å…³é”®è¯
    'å¤§æ¨¡å‹': 8, 'å¤§è¯­è¨€æ¨¡å‹': 8, 'äººå·¥æ™ºèƒ½': 4, 'æœºå™¨å­¦ä¹ ': 4,
    'æ·±åº¦å­¦ä¹ ': 5, 'å¾®è°ƒ': 6, 'æ¨ç†': 5, 'æ™ºèƒ½ä½“': 6,

    # Crypto / é‡åŒ–
    'bitcoin': 6, 'btc': 5, 'ethereum': 6, 'eth': 5, 'solana': 5, 'sol': 4,
    'defi': 7, 'web3': 5, 'blockchain': 5, 'smart contract': 6,
    'trading': 6, 'quantitative': 7, 'quant': 7, 'algo trading': 8,
    'algorithmic trading': 8, 'backtest': 7, 'alpha': 6, 'strategy': 4,
    'market making': 7, 'mev': 6, 'dex': 5, 'cex': 4,
    'yield': 5, 'staking': 4, 'airdrop': 3,
    # ä¸­æ–‡é‡åŒ–å…³é”®è¯
    'é‡åŒ–': 8, 'é‡åŒ–äº¤æ˜“': 8, 'å›æµ‹': 7, 'ç­–ç•¥': 5, 'å¥—åˆ©': 6,
    'æ¯”ç‰¹å¸': 6, 'ä»¥å¤ªåŠ': 6, 'åŠ å¯†è´§å¸': 5, 'åŒºå—é“¾': 5,

    # å¼€å‘å·¥å…·
    'rust': 4, 'python': 3, 'typescript': 3, 'developer tool': 5,
    'cli': 4, 'api': 3, 'framework': 3, 'library': 3,
    'gpu': 5, 'cuda': 5, 'mlx': 5, 'tpu': 4,
}


class RelevanceScorer:
    """
    BM25 é£æ ¼çš„æ–‡æœ¬ç›¸å…³æ€§æ‰“åˆ†å™¨ï¼ˆçº¯ Python å®ç°ï¼‰

    åŸºäºè€æ¿å…³æ³¨é¢†åŸŸå…³é”®è¯ï¼Œç»™æ¯æ¡æ–°é—»æ‰“ç›¸å…³æ€§åˆ†
    """

    def __init__(self, interest_keywords: dict = None, k1: float = 1.5, b: float = 0.75):
        self.keywords = interest_keywords or OWNER_INTEREST_KEYWORDS
        self.k1 = k1
        self.b = b

    def score(self, item: Item) -> float:
        """
        è®¡ç®—å•æ¡ item çš„ç›¸å…³æ€§åˆ†æ•°

        Returns:
            float: ç›¸å…³æ€§åˆ†æ•°ï¼ˆ0~100ï¼‰
        """
        text = f"{item.title} {item.title} {item.text}".lower()  # æ ‡é¢˜æƒé‡ x2
        text_len = len(text.split())
        avg_len = 200  # å‡è®¾å¹³å‡æ–‡æ¡£é•¿åº¦

        total_score = 0.0

        for keyword, weight in self.keywords.items():
            keyword_lower = keyword.lower()

            # ç»Ÿè®¡è¯é¢‘
            if ' ' in keyword_lower:
                tf = text.count(keyword_lower)
            else:
                tf = len(re.findall(r'\b' + re.escape(keyword_lower) + r'\b', text))

            if tf == 0:
                continue

            # BM25 å…¬å¼ï¼ˆç®€åŒ–ç‰ˆï¼ŒIDF ç”¨ keyword weight æ›¿ä»£ï¼‰
            idf = weight  # ç”¨äººå·¥æƒé‡æ›¿ä»£ IDF
            norm_tf = (tf * (self.k1 + 1)) / (tf + self.k1 * (1 - self.b + self.b * text_len / avg_len))
            total_score += idf * norm_tf

        return total_score


class DedupEngine:
    """
    å»é‡å¼•æ“ - åŸºäºæ ‡é¢˜ Jaccard ç›¸ä¼¼åº¦åˆå¹¶é‡å¤æ–°é—»
    """

    def __init__(self, threshold: float = 0.5):
        """
        Args:
            threshold: Jaccard ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™è§†ä¸ºé‡å¤
        """
        self.threshold = threshold

    def _tokenize(self, text: str) -> set:
        """å°†æ ‡é¢˜åˆ†è¯ä¸º token é›†åˆ"""
        text = text.lower()
        # è‹±æ–‡æŒ‰ç©ºæ ¼/æ ‡ç‚¹åˆ†è¯
        tokens = set(re.findall(r'[a-z0-9\u4e00-\u9fff]+', text))
        # ä¸­æ–‡æŒ‰å­—åˆ†è¯ï¼ˆç®€å•ä½†æœ‰æ•ˆï¼‰
        chinese_chars = set(re.findall(r'[\u4e00-\u9fff]', text))
        tokens.update(chinese_chars)
        return tokens

    def _jaccard(self, set_a: set, set_b: set) -> float:
        """è®¡ç®— Jaccard ç›¸ä¼¼åº¦"""
        if not set_a or not set_b:
            return 0.0
        intersection = set_a & set_b
        union = set_a | set_b
        return len(intersection) / len(union)

    def deduplicate(self, items: List[Item]) -> List[Item]:
        """
        å»é‡ï¼šä¿ç•™æ¯ç»„é‡å¤ä¸­å¾—åˆ†æœ€é«˜çš„

        Returns:
            å»é‡åçš„ Item åˆ—è¡¨
        """
        if not items:
            return items

        # é¢„è®¡ç®—æ‰€æœ‰æ ‡é¢˜çš„ token é›†åˆ
        token_sets = [(item, self._tokenize(item.title)) for item in items]

        kept = []
        removed_count = 0

        for i, (item, tokens) in enumerate(token_sets):
            is_duplicate = False
            for j, kept_item in enumerate(kept):
                kept_tokens = self._tokenize(kept_item.title)
                sim = self._jaccard(tokens, kept_tokens)
                if sim >= self.threshold:
                    # é‡å¤äº†ï¼Œä¿ç•™å¾—åˆ†é«˜çš„
                    if item.score > kept_item.score:
                        kept[j] = item
                    is_duplicate = True
                    removed_count += 1
                    break

            if not is_duplicate:
                kept.append(item)

        if removed_count > 0:
            print(f"     ğŸ”„ å»é‡: åˆå¹¶äº† {removed_count} æ¡é‡å¤å†…å®¹")

        return kept


class SmartFilter:
    """
    æ™ºèƒ½è¿‡æ»¤å™¨ - æ”¯æŒå¤šç§å¯æ’æ‹”çš„è¿‡æ»¤ç­–ç•¥ + BM25 ç²—æ’ + å€™é€‰æ± 

    ç‰¹æ€§:
    - æŒ‰é¢‘é“åº”ç”¨ä¸åŒç­–ç•¥
    - BM25 ç›¸å…³æ€§ç²—æ’ï¼ˆåŸºäºè€æ¿å…´è¶£ï¼‰
    - å€™é€‰æ± æœºåˆ¶ï¼ˆä½åˆ†å†…å®¹å¤‡ç”¨ï¼‰
    - æ ‡é¢˜å»é‡
    - å®Œå…¨å¯æ‰©å±•ï¼ˆæ·»åŠ æ–°ç­–ç•¥åªéœ€ç»§æ‰¿ FilterStrategyï¼‰
    """

    def __init__(self, config: dict):
        self.config = config
        self.channels = config.get('channels', {})
        self.defaults = config.get('defaults', {})
        self.relevance_scorer = RelevanceScorer()
        self.dedup_engine = DedupEngine(threshold=0.5)

    def filter_items(self, items: List[Item], max_age_hours: int = 48) -> List[Item]:
        """
        åº”ç”¨è¿‡æ»¤ç­–ç•¥ + ç²—æ’ + å€™é€‰æ±  + å»é‡

        Args:
            items: è¦è¿‡æ»¤çš„ Item åˆ—è¡¨
            max_age_hours: æœ€å¤§æ—¶æ•ˆï¼ˆå°æ—¶ï¼‰

        Returns:
            é€šè¿‡è¿‡æ»¤çš„ Item åˆ—è¡¨ï¼ˆå¸¦å¾—åˆ†ï¼‰
        """
        print(f"\nğŸ” è¿‡æ»¤ {len(items)} æ¡æ•°æ®...")
        print(f"   å·²æ³¨å†Œç­–ç•¥: {list(FILTER_REGISTRY.keys())}")

        # Step 0: å…¨å±€å»é‡
        items = self.dedup_engine.deduplicate(items)

        # æŒ‰é¢‘é“åˆ†ç»„
        by_channel = {}
        for item in items:
            by_channel.setdefault(item.channel, []).append(item)

        filtered = []
        candidate_pool = []  # å€™é€‰æ± 

        # å¯¹æ¯ä¸ªé¢‘é“åº”ç”¨ç­–ç•¥
        for channel in sorted(by_channel.keys()):
            channel_items = by_channel[channel]
            ch_config = self._get_channel_config(channel)
            strategy_name = ch_config.get('strategy', 'keyword_score')

            print(f"  ğŸ“ é¢‘é“ '{channel}': {len(channel_items)} æ¡, ç­–ç•¥='{strategy_name}'")

            # æ—¶æ•ˆæ€§è¿‡æ»¤
            time_filtered = [
                item for item in channel_items
                if is_within_hours(item.published_at, max_age_hours)
            ]

            if len(time_filtered) < len(channel_items):
                print(f"     â° æ—¶æ•ˆè¿‡æ»¤: {len(time_filtered)}/{len(channel_items)} åœ¨ {max_age_hours}h å†…")

            # Step 1: BM25 ç›¸å…³æ€§ç²—æ’æ‰“åˆ†
            for item in time_filtered:
                relevance = self.relevance_scorer.score(item)
                item.metadata['relevance_score'] = relevance

            # åº”ç”¨åŸæœ‰è¿‡æ»¤ç­–ç•¥
            try:
                filter_class = get_filter(strategy_name)
                filter_instance = filter_class(ch_config)

                passed = []
                candidates = []

                for item in time_filtered:
                    score = filter_instance.filter(item)
                    relevance = item.metadata.get('relevance_score', 0)

                    if score is not None:
                        # ç»¼åˆå¾—åˆ† = åŸå§‹ç­–ç•¥å¾—åˆ† + ç›¸å…³æ€§åŠ æˆ
                        combined_score = score + relevance * 0.1
                        item.score = combined_score
                        item.filtered = True
                        passed.append(item)
                    elif relevance > 10:
                        # åŸå§‹ç­–ç•¥æ²¡é€šè¿‡ï¼Œä½†ç›¸å…³æ€§é«˜ â†’ è¿›å€™é€‰æ± 
                        item.score = relevance * 0.1
                        item.filtered = True
                        candidates.append(item)

                filtered.extend(passed)
                candidate_pool.extend(candidates)

                print(f"     âœ“ é€šè¿‡: {len(passed)}/{len(time_filtered)}, å€™é€‰æ± : +{len(candidates)}")

            except Exception as e:
                print(f"     âœ— ç­–ç•¥ '{strategy_name}' å¤±è´¥: {e}")

        # Step 2: å€™é€‰æ± è¡¥å……ï¼ˆå¦‚æœé«˜åˆ†å†…å®¹ä¸å¤Ÿï¼‰
        min_total = 30  # æœ€å°‘æœŸæœ›æ¡æ•°
        if len(filtered) < min_total and candidate_pool:
            # æŒ‰ç›¸å…³æ€§æ’åºå€™é€‰æ± 
            candidate_pool.sort(key=lambda x: x.metadata.get('relevance_score', 0), reverse=True)
            supplement_count = min(min_total - len(filtered), len(candidate_pool))
            supplement = candidate_pool[:supplement_count]
            filtered.extend(supplement)
            print(f"\n  ğŸ“¦ å€™é€‰æ± è¡¥å……: +{supplement_count} æ¡ (æ€»è®¡ {len(filtered)} æ¡)")

        # Step 3: é¢‘é“å†…å»é‡
        filtered = self.dedup_engine.deduplicate(filtered)

        print(f"\nâœ… è¿‡æ»¤å®Œæˆ: {len(filtered)} æ¡")
        return filtered

    def _get_channel_config(self, channel: str) -> dict:
        """
        è·å–é¢‘é“é…ç½®ï¼Œæ”¯æŒå…³é”®è¯ç»§æ‰¿

        é…ç½®ç¤ºä¾‹:
        ```yaml
        channels:
          tech:
            keywords:
              _inherit: [ai]  # ç»§æ‰¿ ai é¢‘é“çš„å…³é”®è¯
              programming: 3
        ```
        """
        if channel in self.channels:
            config = dict(self.channels[channel])

            # å¤„ç†å…³é”®è¯ç»§æ‰¿
            if 'keywords' in config and '_inherit' in config['keywords']:
                inherit_from = config['keywords']['_inherit']
                inherited_keywords = {}

                # ä»å…¶ä»–é¢‘é“ç»§æ‰¿å…³é”®è¯
                for parent_channel in inherit_from:
                    if parent_channel in self.channels:
                        parent_keywords = self.channels[parent_channel].get('keywords', {})
                        inherited_keywords.update(parent_keywords)

                # ç§»é™¤ _inherit æ ‡è®°
                del config['keywords']['_inherit']

                # åˆå¹¶ç»§æ‰¿çš„å’Œè‡ªå·±çš„å…³é”®è¯ï¼ˆè‡ªå·±çš„ä¼˜å…ˆï¼‰
                merged_keywords = inherited_keywords.copy()
                merged_keywords.update(config['keywords'])
                config['keywords'] = merged_keywords

            return config

        return self.defaults.copy()

    def save_filtered_data(self, items: List[Item], output_path: Path):
        """ä¿å­˜è¿‡æ»¤åçš„æ•°æ®åˆ° JSONL"""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            for item in items:
                f.write(json.dumps(item.to_dict(), ensure_ascii=False) + '\n')

        print(f"ğŸ’¾ å·²ä¿å­˜è¿‡æ»¤æ•°æ®: {output_path}")

    def load_filtered_data(self, input_path: Path) -> List[Item]:
        """ä» JSONL åŠ è½½è¿‡æ»¤åçš„æ•°æ®"""
        items = []

        with open(input_path, encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data = json.loads(line)
                    items.append(Item.from_dict(data))

        return items


def create_custom_filter(name: str, score_func):
    """
    å¿«é€Ÿåˆ›å»ºè‡ªå®šä¹‰è¿‡æ»¤ç­–ç•¥çš„è¾…åŠ©å‡½æ•°

    ç¤ºä¾‹:
    ```python
    # åˆ›å»ºä¸€ä¸ªåªçœ‹æ ‡é¢˜çš„è¿‡æ»¤å™¨
    def title_only_score(item):
        if 'important' in item.title.lower():
            return 10
        return 0

    create_custom_filter('title_only', title_only_score)
    ```
    """
    from .filters.base import FilterStrategy
    from .filters import register_filter

    class CustomFilter(FilterStrategy):
        def calculate_score(self, item):
            return score_func(item)

    register_filter(name, CustomFilter)
    return CustomFilter
