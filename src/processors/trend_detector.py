"""è¶‹åŠ¿æ£€æµ‹å™¨ â€” è·¨å¤©å…³é”®è¯çƒ­åº¦è¿½è¸ª"""

import json
import re
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from collections import Counter


class TrendDetector:
    """
    åŸºäºå…³é”®è¯é¢‘ç‡çš„è¶‹åŠ¿æ£€æµ‹
    
    åŸç†ï¼š
    1. ä»ä»Šæ—¥ briefs æå–å…³é”®è¯ï¼ˆheadline + tagsï¼‰
    2. ä»å†å²æ•°æ®ï¼ˆå‰ N å¤©çš„ analyzed JSONï¼‰æå–å…³é”®è¯
    3. å¯¹æ¯”é¢‘ç‡å˜åŒ–ï¼Œæ ‡æ³¨ trending up / trending down / new
    """
    
    def __init__(self, data_dir: str = "data", lookback_days: int = 7):
        self.data_dir = Path(data_dir)
        self.lookback_days = lookback_days
    
    def detect(self, today_briefs: Dict[str, List[Dict]], today_date: str = None) -> List[Dict]:
        """
        æ£€æµ‹è¶‹åŠ¿
        
        Args:
            today_briefs: ä»Šæ—¥çš„ {section: [briefs]} æ•°æ®
            today_date: æ—¥æœŸå­—ç¬¦ä¸² YYYY-MM-DDï¼ˆé»˜è®¤ä»Šå¤©ï¼‰
            
        Returns:
            List[Dict]: è¶‹åŠ¿åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«:
                - keyword: str
                - trend: "ğŸ”¥ rising" | "ğŸ“ˆ steady" | "ğŸ†• new" | "ğŸ“‰ declining"  
                - today_count: int
                - avg_count: float
                - change_pct: float
                - related_headlines: List[str] (æœ€å¤š3æ¡)
        """
        if today_date is None:
            today_date = datetime.now().strftime("%Y-%m-%d")
        
        # 1. æå–ä»Šæ—¥å…³é”®è¯
        today_keywords = self._extract_keywords(today_briefs)
        
        # 2. åŠ è½½å†å²æ•°æ®å¹¶æå–å…³é”®è¯
        historical = self._load_historical(today_date)
        
        if not historical:
            # æ²¡æœ‰å†å²æ•°æ®ï¼Œå…¨éƒ¨æ ‡ä¸º new
            return [
                {
                    "keyword": kw,
                    "trend": "ğŸ†• new",
                    "today_count": count,
                    "avg_count": 0,
                    "change_pct": 100,
                    "related_headlines": self._find_headlines(kw, today_briefs)[:3]
                }
                for kw, count in today_keywords.most_common(15)
            ]
        
        # 3. è®¡ç®—å†å²å¹³å‡
        avg_keywords = Counter()
        for day_kws in historical.values():
            for kw, count in day_kws.items():
                avg_keywords[kw] += count
        
        num_days = len(historical)
        for kw in avg_keywords:
            avg_keywords[kw] /= num_days
        
        # 4. å¯¹æ¯”
        trends = []
        all_keywords = set(today_keywords.keys()) | set(avg_keywords.keys())
        
        for kw in all_keywords:
            today_count = today_keywords.get(kw, 0)
            avg_count = avg_keywords.get(kw, 0)
            
            if today_count == 0:
                continue  # ä»Šå¤©æ²¡å‡ºç°çš„ä¸æŠ¥
            
            if avg_count == 0:
                trend = "ğŸ†• new"
                change_pct = 100
            elif today_count >= avg_count * 2:
                trend = "ğŸ”¥ rising"
                change_pct = ((today_count - avg_count) / avg_count) * 100
            elif today_count >= avg_count * 0.8:
                trend = "ğŸ“ˆ steady"
                change_pct = ((today_count - avg_count) / avg_count) * 100
            else:
                trend = "ğŸ“‰ declining"
                change_pct = ((today_count - avg_count) / avg_count) * 100
            
            trends.append({
                "keyword": kw,
                "trend": trend,
                "today_count": today_count,
                "avg_count": round(avg_count, 1),
                "change_pct": round(change_pct, 1),
                "related_headlines": self._find_headlines(kw, today_briefs)[:3]
            })
        
        # æŒ‰å˜åŒ–å¹…åº¦æ’åºï¼Œrising ä¼˜å…ˆ
        trend_priority = {"ğŸ”¥ rising": 0, "ğŸ†• new": 1, "ğŸ“ˆ steady": 2, "ğŸ“‰ declining": 3}
        trends.sort(key=lambda x: (trend_priority.get(x["trend"], 9), -abs(x["change_pct"])))
        
        return trends[:20]  # Top 20
    
    def save_today_keywords(self, briefs: Dict[str, List[Dict]], date: str = None):
        """ä¿å­˜ä»Šæ—¥å…³é”®è¯åˆ°å†å²æ•°æ®ï¼ˆä¾›æœªæ¥å¯¹æ¯”ï¼‰"""
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")
        
        keywords = self._extract_keywords(briefs)
        
        history_dir = self.data_dir / "trend_history"
        history_dir.mkdir(parents=True, exist_ok=True)
        
        filepath = history_dir / f"{date}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(dict(keywords), f, ensure_ascii=False, indent=2)
    
    def _extract_keywords(self, briefs: Dict[str, List[Dict]]) -> Counter:
        """ä» briefs ä¸­æå–å…³é”®è¯é¢‘ç‡"""
        keywords = Counter()
        
        for section, items in briefs.items():
            if section.startswith('__') or not isinstance(items, list):
                continue
            for item in items:
                # ä» headline æå–
                headline = item.get('headline', '')
                words = self._tokenize(headline)
                keywords.update(words)
                
                # ä» tags æå–
                tags = item.get('category_tags', [])
                keywords.update([t.lower().strip() for t in tags if len(t) > 1])
        
        return keywords
    
    def _tokenize(self, text: str) -> List[str]:
        """ç®€å•åˆ†è¯ï¼šæå–æœ‰æ„ä¹‰çš„è¯ï¼ˆ2+ å­—ç¬¦ï¼Œè¿‡æ»¤åœç”¨è¯ï¼‰"""
        stopwords = {
            'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
            'could', 'should', 'may', 'might', 'can', 'shall', 'must',
            'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',
            'as', 'into', 'through', 'during', 'before', 'after', 'above',
            'below', 'between', 'out', 'off', 'over', 'under', 'again',
            'further', 'then', 'once', 'here', 'there', 'when', 'where',
            'why', 'how', 'all', 'each', 'every', 'both', 'few', 'more',
            'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only',
            'own', 'same', 'so', 'than', 'too', 'very', 'just', 'because',
            'but', 'and', 'or', 'if', 'while', 'about', 'up', 'down',
            'new', 'what', 'that', 'this', 'its', 'it', 'your', 'their',
            'our', 'my', 'his', 'her', 'who', 'which',
            # ä¸­æ–‡åœç”¨è¯
            'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'åœ¨', 'ä¸', 'æœ‰', 'æˆ‘', 'ä»–', 'è¿™',
            'ä¸­', 'å¤§', 'æ¥', 'ä¸Š', 'ä¸ª', 'è¦', 'å°±', 'ä¸', 'åŠ', 'ç­‰',
        }
        
        # è‹±æ–‡åˆ†è¯
        words = re.findall(r'[a-zA-Z]{2,}', text.lower())
        # ä¸­æ–‡ï¼šæå–2-4å­—ç»„åˆï¼ˆç®€å• bigram/trigramï¼‰
        chinese_chars = re.findall(r'[\u4e00-\u9fff]{2,4}', text)
        
        result = [w for w in words if w not in stopwords and len(w) > 2]
        result.extend([c for c in chinese_chars if c not in stopwords])
        
        return result
    
    def _load_historical(self, today_date: str) -> Dict[str, Counter]:
        """åŠ è½½å†å²Nå¤©çš„å…³é”®è¯æ•°æ®"""
        history_dir = self.data_dir / "trend_history"
        if not history_dir.exists():
            return {}
        
        today = datetime.strptime(today_date, "%Y-%m-%d")
        historical = {}
        
        for i in range(1, self.lookback_days + 1):
            date = (today - timedelta(days=i)).strftime("%Y-%m-%d")
            filepath = history_dir / f"{date}.json"
            if filepath.exists():
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    historical[date] = Counter(data)
        
        return historical
    
    def _find_headlines(self, keyword: str, briefs: Dict[str, List[Dict]]) -> List[str]:
        """æ‰¾åˆ°åŒ…å«å…³é”®è¯çš„ headlines"""
        headlines = []
        kw_lower = keyword.lower()
        
        for section, items in briefs.items():
            if section.startswith('__') or not isinstance(items, list):
                continue
            for item in items:
                headline = item.get('headline', '')
                if kw_lower in headline.lower() or kw_lower in ' '.join(item.get('category_tags', [])).lower():
                    headlines.append(headline)
        
        return headlines