"""Layer 3: AI åˆ†æå™¨ - Claude åŒpasså¤„ç† + Executive Summary"""

import json
from typing import List, Dict
from pathlib import Path
from collections import defaultdict

from sources.base import Item
from ai.claude import ClaudeClient
from ai.prompts import PromptTemplates


class AIAnalyzer:
    """
    AI åˆ†æå™¨ - Claude åŒpasså¤„ç† (v0.2.0 å¢å¼ºç‰ˆ)

    æ•´åˆ morning-brief å’Œ twitter-watchdog çš„æœ€ä½³å®è·µ:
    - Pass 1: æ™ºèƒ½è¿‡æ»¤ï¼ˆè¯†åˆ«é«˜è´¨é‡å†…å®¹ï¼‰
    - Pass 2: ç»“æ„åŒ–æå–ï¼ˆç”Ÿæˆ headline + detail + importance + tags + insightï¼‰
    - Executive Summary: AI ç”Ÿæˆä»Šæ—¥è¦é—»æ¦‚è¿°
    - Token-aware æ‰¹å¤„ç†
    """

    def __init__(self, claude_client: ClaudeClient, language: str = "zh-CN", config: dict = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            claude_client: Claude å®¢æˆ·ç«¯å®ä¾‹
            language: è¯­è¨€ï¼ˆzh-CN æˆ– en-USï¼‰
            config: å¯é€‰é…ç½® (max_items_per_section ç­‰)
        """
        self.claude = claude_client
        self.language = language
        self.config = config or {}

    def analyze(self, items: List[Item], two_pass: bool = True,
                section_configs: dict = None) -> Dict[str, List[Dict]]:
        """
        åˆ†æ items å¹¶ç”Ÿæˆç»“æ„åŒ–è¾“å‡º

        Args:
            items: è¦åˆ†æçš„ Item åˆ—è¡¨
            two_pass: æ˜¯å¦ä½¿ç”¨åŒpasså¤„ç†
            section_configs: section é…ç½®ï¼ˆç”¨äºç”Ÿæˆ Executive Summaryï¼‰

        Returns:
            Dict[section, List[brief]]: æŒ‰ section åˆ†ç»„çš„ briefs
            ç‰¹æ®Š key "__executive_summary__" å­˜æ”¾ AI ç”Ÿæˆçš„æ¦‚è¿°
        """
        print(f"\nğŸ§  AI åˆ†æä¸­...")
        print(f"   æ¨¡å‹: {self.claude.model}")
        print(f"   åŒpass: {two_pass}")

        # æŒ‰ section åˆ†ç»„
        by_section = self._group_by_section(items)

        results = {}

        for section, section_items in by_section.items():
            print(f"\n  ğŸ“ åˆ†æ section '{section}': {len(section_items)} æ¡")

            # é™æµï¼šæŒ‰ score é™åºå– top Nï¼ˆé»˜è®¤ 30ï¼Œå¯é€šè¿‡ config é…ç½®ï¼‰
            max_per_section = self.config.get('max_items_per_section', 30)
            if len(section_items) > max_per_section:
                section_items = sorted(section_items, key=lambda x: x.score, reverse=True)[:max_per_section]
                print(f"     ğŸ“Š é™æµ: å– top {max_per_section} æ¡ï¼ˆæŒ‰ score æ’åºï¼‰")

            if two_pass:
                # Pass 1: è¿‡æ»¤
                filtered_items = self._pass1_filter(section_items, section)
                print(f"     âœ“ Pass 1 è¿‡æ»¤: {len(filtered_items)}/{len(section_items)}")

                # Pass 2: æå–
                if filtered_items:
                    briefs = self._pass2_extract(filtered_items, section)
                    results[section] = briefs
                    print(f"     âœ“ Pass 2 æå–: {len(briefs)} æ¡ briefs")
            else:
                # å•passï¼šç›´æ¥æå–
                briefs = self._pass2_extract(section_items, section)
                results[section] = briefs
                print(f"     âœ“ æå–: {len(briefs)} æ¡ briefs")

        # æŒ‰ importance æ’åºæ¯ä¸ª section
        for section in results:
            results[section] = sorted(
                results[section],
                key=lambda x: x.get('importance', 3),
                reverse=True
            )

        # ç”Ÿæˆ"ä¸ªäººå…³æ³¨"æ¿å— â€” ä»å…¶ä»– section é«˜åˆ†å†…å®¹ä¸­äºŒæ¬¡ç­›é€‰
        if section_configs and 'personal' in section_configs:
            try:
                personal_briefs = self._build_personal_section(results)
                if personal_briefs:
                    results['personal'] = personal_briefs
                    print(f"\n  ğŸ¯ ä¸ªäººå…³æ³¨: {len(personal_briefs)} æ¡")
            except Exception as e:
                print(f"\n  âš ï¸  ä¸ªäººå…³æ³¨ç”Ÿæˆå¤±è´¥: {e}")

        # ç”Ÿæˆ Executive Summary
        if section_configs and self.claude:
            try:
                executive_summary = self._generate_executive_summary(results, section_configs)
                if executive_summary:
                    results['__executive_summary__'] = executive_summary
                    print(f"\n  ğŸ“ Executive Summary å·²ç”Ÿæˆ ({len(executive_summary)} å­—)")
            except Exception as e:
                print(f"\n  âš ï¸  Executive Summary ç”Ÿæˆå¤±è´¥: {e}")

        total_briefs = sum(len(b) for k, b in results.items() if k != '__executive_summary__')
        print(f"\nâœ… AI åˆ†æå®Œæˆ: {total_briefs} æ¡ briefs")
        return results

    def _group_by_section(self, items: List[Item]) -> Dict[str, List[Item]]:
        """æŒ‰ section/channel åˆ†ç»„"""
        by_section = defaultdict(list)

        for item in items:
            section = item.channel
            by_section[section].append(item)

        return dict(by_section)

    def _pass1_filter(self, items: List[Item], section: str) -> List[Item]:
        """
        Pass 1: AI è¿‡æ»¤

        ä½¿ç”¨ Claude è¯†åˆ«é«˜è´¨é‡å†…å®¹
        """
        # Token-aware åˆ†æ‰¹
        batches = self.claude.batch_items_by_tokens(items, max_tokens=80000)

        filtered_items = []

        for batch_idx, batch in enumerate(batches):
            if len(batches) > 1:
                print(f"     ğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)}: {len(batch)} æ¡")

            # ç”Ÿæˆ prompt
            prompt = PromptTemplates.filter_prompt(batch, section, self.language)

            # è°ƒç”¨ Claude
            try:
                response = self.claude.call(
                    prompt=prompt,
                    max_tokens=1000,
                    temperature=0.2
                )

                # è§£æ IDs
                selected_ids = self._parse_ids(response)

                # æå–å¯¹åº”çš„ items
                for item_id in selected_ids:
                    if 0 <= item_id < len(batch):
                        filtered_items.append(batch[item_id])

            except Exception as e:
                print(f"     âš ï¸  Pass 1 å¤±è´¥: {e}")
                # å¤±è´¥æ—¶ä¿ç•™æ‰€æœ‰items
                filtered_items.extend(batch)

        return filtered_items

    def _pass2_extract(self, items: List[Item], section: str) -> List[Dict]:
        """
        Pass 2: ç»“æ„åŒ–æå–ï¼ˆv0.2.0 å¢å¼ºç‰ˆï¼‰

        ä½¿ç”¨ Claude ç”Ÿæˆ headline + detail + importance + category_tags + insight
        papers section ä½¿ç”¨ä¸“ç”¨ promptï¼Œé¢å¤–æå– authors/arxiv_id/research_tags/practicality_score
        """
        is_papers = section == 'papers'

        # å¦‚æœå†…å®¹å¤ªå¤šï¼Œåˆ†æ‰¹å¤„ç†
        batches = self.claude.batch_items_by_tokens(items, max_tokens=80000)

        all_briefs = []

        for batch_idx, batch in enumerate(batches):
            if len(batches) > 1:
                print(f"     ğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)}: {len(batch)} æ¡")

            # ç”Ÿæˆ prompt â€” papers section ä½¿ç”¨ä¸“ç”¨ prompt
            if is_papers:
                prompt = PromptTemplates.extract_prompt_papers(batch, section, self.language)
            else:
                prompt = PromptTemplates.extract_prompt(batch, section, self.language)

            # è°ƒç”¨ Claudeï¼ˆJSON è¾“å‡ºï¼‰
            try:
                briefs = self.claude.call_with_json(
                    prompt=prompt,
                    max_tokens=8192,
                    temperature=0.3
                )

                # éªŒè¯æ ¼å¼
                brief_list = []
                if isinstance(briefs, list):
                    brief_list = briefs
                elif isinstance(briefs, dict) and 'items' in briefs:
                    brief_list = briefs['items']

                for brief in brief_list:
                    # é€šç”¨å­—æ®µé»˜è®¤å€¼
                    brief.setdefault('importance', 3)
                    brief.setdefault('category_tags', [])
                    brief.setdefault('insight', '')
                    # papers ä¸“ç”¨å­—æ®µé»˜è®¤å€¼
                    if is_papers:
                        brief.setdefault('authors', '')
                        brief.setdefault('arxiv_id', '')
                        brief.setdefault('research_tags', [])
                        brief.setdefault('practicality_score', 3)

                all_briefs.extend(brief_list)

            except Exception as e:
                print(f"     âš ï¸  Pass 2 å¤±è´¥: {e}")
                # å¤±è´¥æ—¶ä½¿ç”¨ç®€å•æ ¼å¼ï¼Œpapers é¢å¤–ä» metadata å›å¡«å­—æ®µ
                for item in batch:
                    meta = getattr(item, 'metadata', {}) or {}
                    display_source = meta.get('feed_name') or meta.get('feed_title') or item.source
                    fallback = {
                        'headline': item.title,
                        'detail': item.text[:200],
                        'url': item.url,
                        'source': display_source,
                        'importance': 3,
                        'category_tags': [],
                        'insight': ''
                    }
                    if is_papers:
                        # ä» Item metadata å›å¡«è®ºæ–‡ä¸“ç”¨å­—æ®µ
                        authors = meta.get('authors', [])
                        author_str = ', '.join(authors[:3])
                        if len(authors) > 3:
                            author_str += ' et al.'
                        fallback['authors'] = author_str
                        fallback['arxiv_id'] = meta.get('arxiv_id', '')
                        fallback['research_tags'] = meta.get('categories', [])[:4]
                        fallback['practicality_score'] = 3
                    all_briefs.append(fallback)

        return all_briefs

    # ============================================================
    # ä¸ªäººå…³æ³¨æ¿å— â€” ä»å…¨å±€é«˜åˆ†å†…å®¹ä¸­äºŒæ¬¡ç­›é€‰
    # ============================================================

    # å…³é”®è¯é›†åˆï¼šåŒ¹é…åˆ°ä»»æ„ä¸€ä¸ªå³å…¥é€‰å€™é€‰
    PERSONAL_KEYWORDS = [
        # é‡åŒ–äº¤æ˜“
        "quant", "quantitative", "algorithmic trading", "algo trading",
        "backtesting", "backtest", "alpha", "market making", "arbitrage",
        "trading strategy", "order book", "é«˜é¢‘", "é‡åŒ–", "å¥—åˆ©", "å›æµ‹",
        "ç­–ç•¥", "algotrading",
        # Crypto DeFi
        "defi", "dex", "amm", "liquidity pool", "yield", "staking",
        "mev", "flashbots", "uniswap", "aave", "compound", "lido",
        "restaking", "eigenlayer", "pendle", "ethena",
        "layer 2", "rollup", "zk-proof", "zk-snark",
        "on-chain", "é“¾ä¸Š", "å»ä¸­å¿ƒåŒ–é‡‘è",
        # AI Agent / å·¥å…·é“¾
        "ai agent", "agent framework", "langchain", "langgraph",
        "autogpt", "crewai", "tool use", "function calling",
        "mcp", "model context protocol",
        "cursor", "copilot", "aider", "coding assistant",
        "openai api", "claude api", "anthropic api",
    ]

    def _build_personal_section(self, results: Dict[str, List[Dict]]) -> List[Dict]:
        """
        ä»æ‰€æœ‰ section çš„é«˜åˆ† briefs ä¸­ç­›é€‰å‡ºä¸è€æ¿ä¸ªäººå…´è¶£æœ€ç›¸å…³çš„å†…å®¹ã€‚

        ç­›é€‰é€»è¾‘ï¼š
        1. æ”¶é›†æ‰€æœ‰ section ä¸­ importance >= 3 çš„ briefs
        2. å…³é”®è¯åŒ¹é…ï¼ˆheadline + detail + tags ä¸­å‘½ä¸­ä¸ªäººå…´è¶£å…³é”®è¯ï¼‰
        3. æŒ‰ importance é™åºï¼Œå– top 8
        """
        import re

        candidates = []

        for section, briefs in results.items():
            if section.startswith('__') or not isinstance(briefs, list):
                continue
            for brief in briefs:
                importance = brief.get('importance', 3)
                if importance < 3:
                    continue

                # æ‹¼æ¥æ£€ç´¢æ–‡æœ¬
                search_text = " ".join([
                    brief.get('headline', ''),
                    brief.get('detail', ''),
                    " ".join(brief.get('category_tags', [])),
                    brief.get('insight', ''),
                ]).lower()

                # å…³é”®è¯åŒ¹é…
                match_count = 0
                for kw in self.PERSONAL_KEYWORDS:
                    if kw.lower() in search_text:
                        match_count += 1

                if match_count > 0:
                    candidates.append({
                        **brief,
                        '_match_count': match_count,
                        '_source_section': section,
                    })

        # æŒ‰åŒ¹é…æ•° Ã— importance æ’åº
        candidates.sort(
            key=lambda x: x['_match_count'] * x.get('importance', 3),
            reverse=True
        )

        # å– top 8ï¼Œå»æ‰å†…éƒ¨å­—æ®µ
        personal = []
        seen_urls = set()
        for c in candidates:
            url = c.get('url', '')
            if url in seen_urls:
                continue
            seen_urls.add(url)

            # å»é™¤å†…éƒ¨å­—æ®µ
            item = {k: v for k, v in c.items() if not k.startswith('_')}
            personal.append(item)
            if len(personal) >= 8:
                break

        return personal

    def _generate_executive_summary(self, briefs: Dict[str, List[Dict]],
                                     section_configs: dict) -> str:
        """
        ç”Ÿæˆ AI Executive Summary

        Args:
            briefs: æ‰€æœ‰å·²åˆ†æçš„ briefs
            section_configs: section é…ç½®

        Returns:
            str: AI ç”Ÿæˆçš„æ¦‚è¿°æ–‡å­—
        """
        # è¿‡æ»¤æ‰ç‰¹æ®Š key
        content_briefs = {k: v for k, v in briefs.items() if not k.startswith('__')}

        if not content_briefs:
            return ""

        prompt = PromptTemplates.executive_summary_prompt(
            content_briefs, section_configs, self.language
        )

        response = self.claude.call(
            prompt=prompt,
            max_tokens=1000,
            temperature=0.4
        )

        return response.strip()

    def _parse_ids(self, response: str) -> List[int]:
        """
        è§£æ filter prompt çš„å“åº”

        æ”¯æŒæ ¼å¼: "0,3,7,12" æˆ– "NONE"
        """
        response = response.strip()

        # ç©ºå“åº”æˆ– NONE
        if not response or response.upper() == "NONE":
            return []

        # æå–æ•°å­—
        import re
        numbers = re.findall(r'\d+', response)

        try:
            return [int(n) for n in numbers]
        except ValueError:
            return []

    def save_analyzed_data(self, briefs: Dict[str, List[Dict]], output_path: Path):
        """ä¿å­˜åˆ†æç»“æœåˆ° JSON"""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(briefs, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ å·²ä¿å­˜åˆ†ææ•°æ®: {output_path}")

    def load_analyzed_data(self, input_path: Path) -> Dict[str, List[Dict]]:
        """ä» JSON åŠ è½½åˆ†æç»“æœ"""
        with open(input_path, encoding='utf-8') as f:
            return json.load(f)
